{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.- Regresión Lineal Ordinaria (LSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección trabajaremos con un dataset conocido como House Sales in King County, USA, presentado\n",
    "en la plataforma de Kaggle [4], el cual es un gran dataset para evaluar simples modelos de regresión. Los\n",
    "registros contienen distintas características asociadas a las ventas de casas en la localidad King County, entre\n",
    "mayo de 2014 y mayo de 2015, las cuales vienen descritas en el dataset, como la cantidad de habitaciones,\n",
    "cantidad de baños, número de pisos, etc. Donde una de las variables a estudiar corresponde al precio en el\n",
    "cual se vendió la casa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **a)** Construya un dataframe con los datos a analizar descargándolos desde la plataforma como se indicó.\n",
    "Explique por qué se realiza la línea 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"kc_house_data.csv\")\n",
    "df.drop(['id','date','zipcode',],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La línea 4 se encarga de eliminar parámetros que no son importantes para la valoración de la vivienda. La función drop toma un arreglo de atributos y los elimina del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Describa brevemente el dataset a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se mustra en la salida anterior, el dataset corresponde a la información de 21613 casa, en donde cada una tiene 18 atributos asociados. Estos atributos corresponden a precio, número de baños, número de dormitorios, superficie del living, superficie total del terreno, número de pisos, entre otros más especificados en las columnas. Además, se presentan la media, la desviaciñon estándar y los cuartiles de cada atributo sobre el dataset total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Normalice los datos antes de trabajar y aplique una transformación adecuada a la variable a predecir.\n",
    "Explique la importancia/conveniencia de realizar estas dos operaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_scaled['price'] = np.log(df['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "La normalización es necesaria debido a que la mayoría de los algoritmos clasificadores hacen uso de la distancia euclidiana para calcular la distancia entre dos puntos en el dataset. Cuando existe un atributo con un rango de valores mucho mayor en comparación a los demás, este gobernará el calculo de la distancia. Esto puede producir, por ejemplo, que el algoritmo de gradiente (SGD) converja mucho más lento en comparación a una instancia normalizada.\n",
    "\n",
    "La transformación sobre el precio, por otro lado, es necesaria para utilizar regresión lineal. Las regresiones lineales, tal y como dice su nombre, modelan utilizando rectas. Estas rectas luego son comparadas con los valores del precio para probar que tan bien se ajustan a nuestros valores. No tiene sentido realizar esta comapracion si el precio no sigue una tendencia lineal. Por ejemplo, se estaría intentando ajustar una recta sobre una función cuadratica, lo cual no es correcto. Al aplicar el logaritmo, nos aseguramos que el precio, nuestro ** y **, sea siempre lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Realice una regresión lineal de mínimos cuadrados básica. Explique la importancia/conveniencia del\n",
    "paso 4 y los argumentos que se deben entregar a la función que implementa la regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "X = df_scaled.iloc[:,1:] #use .ix instead, in older pandas version\n",
    "N = X.shape[0]\n",
    "X.insert(X.shape[1], 'intercept', np.ones(N))\n",
    "y = df_scaled['price']\n",
    "#mascara estatica con el 70% de los datos\n",
    "mascara = np.zeros(len(X))\n",
    "limit = int(len(X)*0.7)\n",
    "mascara[:limit] = 1\n",
    "istrain = mascara== 1\n",
    "Xtrain = X[istrain]\n",
    "ytrain = y[istrain]\n",
    "Xtest = X[np.logical_not(istrain)]\n",
    "ytest = y[np.logical_not(istrain)]\n",
    "linreg = lm.LinearRegression(fit_intercept = False)\n",
    "linreg.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el paso 4, se incorpora una columna de unos para representar a la constante $\\beta_0$ en el modelo de la regresión lineal. Esta constante proviene de la expresión:\n",
    "\n",
    "$H = \\beta^TX + \\beta_0$\n",
    "\n",
    "en donde $\\beta$ es la matriz de los valores libres asociados con cada atributo en la matriz $X$ y $H$ es la estimación actual.\n",
    "\n",
    "Los parámetros que se deben entregar a la función de regresión lineal, es la matriz de atributos $X$ y el vector de los valores verdaderos $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Construya una tabla con los pesos y Z-score correspondientes a cada predictor (variable). ¿Qué variables\n",
    "están más correlacionadas con la respuesta? Si usáramos un nivel de significación del 5%. ¿Qué es lo\n",
    "que observa y cuál puede ser la causa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención de los pesos\n",
    "betas = linreg.coef_\n",
    "col = list(X)\n",
    "pd.DataFrame([betas], columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los z-score\n",
    "from scipy import stats\n",
    "zscores = stats.zscore(betas)\n",
    "pd.DataFrame([zscores], columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pending\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables que están más relacionadas con el precio corresponden a sqft_living de forma negativa, sqft_above de forma positiva y sqft_basemente de forma positiva. Estas variables son la superficie habitable de la vivienda, la superficie total construida sin contar el sótano y la superficie del sótano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f)** Proponga un método para corregir lo observado (Hint: inspírese en los métodos de feature engineering\n",
    "de las siguiente secciones). Verifíquelo mediante los Z-score presentados en la pregunta **e)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g)** Estime el error de predicción del modelo usando validación cruzada con un número de folds igual a K\n",
    "= 5 y K = 10. Recuerde que para que la estimación sea razonable, en cada configuración (fold) deberá\n",
    "reajustar los pesos del modelo. Mida el error real del modelo sobre el conjunto de pruebas, compare y\n",
    "concluya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = linreg.predict(Xtest)\n",
    "mse_test = np.mean(np.power(yhat_test - ytest, 2))\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10)\n",
    "mse_cv = 0\n",
    "for train, val in kf.split(Xm):\n",
    "    linreg = lm.LinearRegression(fit_intercept = False)\n",
    "    linreg.fit(Xm[train], ym[train])\n",
    "    yhat_val = linreg.predict(Xm[val])\n",
    "    mse_fold = np.mean(np.power(yhat_val - ym[val], 2))\n",
    "    mse_cv += mse_fold\n",
    "mse_cv = mse_cv / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**h)** Mida los errores de predicción para cada dato de entrenamiento. Utilizando un “quantile-quantile plot”\n",
    "determine si es razonable la hipótesis de normalidad sobre los residuos del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2.- Selección de Atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando el dataframe de la actividad anterior,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Construya una función que implemente Forward Step-wise Selection (FSS). Es decir, partiendo con un\n",
    "modelo sin predictores (variables), agregue un predictor a la vez, re-ajustando el modelo de regresión\n",
    "en cada paso. Para seleccionar localmente una variable, proponga/implemente un criterio distinto al\n",
    "utilizado en el código de ejemplo. Construya un gráfico que muestre el error de entrenamiento y el error\n",
    "de pruebas como función del número de variables en el modelo. Ordene el eje x de menor a mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fss(x, y, names_x, k = 10000):\n",
    "    p = x.shape[1]-1\n",
    "    k = min(p, k)\n",
    "    names_x = np.array(names_x)\n",
    "    remaining = range(0, p)\n",
    "    selected = [p]\n",
    "    current_score = best_new_score = 0.0\n",
    "    while remaining and len(selected)<=k :\n",
    "        score_candidates = []\n",
    "        for candidate in remaining:\n",
    "            model = lm.LinearRegression(fit_intercept=False)\n",
    "            indexes = selected + [candidate]\n",
    "            x_train = x[:,indexes]\n",
    "            predictions_train = model.fit(x_train, y).predict(x_train)\n",
    "            residuals_train = predictions_train - y\n",
    "            mse_candidate = np.mean(np.power(residuals_train, 2))\n",
    "            score_candidates.append((mse_candidate, candidate))\n",
    "        score_candidates.sort()\n",
    "        score_candidates[:] = score_candidates[::-1]\n",
    "        best_new_score, best_candidate = score_candidates.pop()\n",
    "        remaining.remove(best_candidate)\n",
    "        selected.append(best_candidate)\n",
    "        print(\"selected = %s ...\"%names_x[best_candidate])\n",
    "        print(\"totalvars=%d, mse = %f\"%(len(indexes),best_new_score))\n",
    "    return selected\n",
    "\n",
    "names_regressors = X.columns[:-1] #without intercept\n",
    "fss(Xm,ym,names_regressors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3.- Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando el dataframe de la actividad anterior,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Ajuste un modelo lineal utilizando “Ridge Regression”, es decir, regularizando con la norma $\\ell_2$. Utilice\n",
    "valores del parámetro de regularización $\\lambda$ en el rango $[10^7, 10^1]$, variando si estima conveniente.\n",
    "Construya un gráfico que muestre los coeficientes obtenidos como función del parámetro de regularización.\n",
    "Describa lo que observa. (WARNING: Note que la línea 3 y el primer argumento en la línea 9\n",
    "son críticos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pylab as plt\n",
    "X2 = X.drop('intercept', axis=1,inplace=False)\n",
    "Xtrain = X2[istrain]\n",
    "ytrain = y[istrain]\n",
    "names_regressors = X2.columns\n",
    "alphas_ = np.logspace(7,1,base=10)\n",
    "coefs = []\n",
    "model = Ridge(fit_intercept=True,solver='svd')\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    coefs.append(model.coef_)\n",
    "ax = plt.gca()\n",
    "for y_arr, label in zip(np.squeeze(coefs).T, names_regressors):\n",
    "    plt.plot(alphas_, y_arr, label=label)\n",
    "plt.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1]) # reverse axis\n",
    "plt.title('Regularization Path RIDGE')\n",
    "plt.axis('tight')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Ajuste un modelo lineal utilizando el método “Lasso”, es decir, regularizando con la norma $\\ell_1$. Utilice\n",
    "valores del parámetro de regularización $\\lambda$ en el rango $[10^0, 10^{-3}]$. Para obtener el código, modifique\n",
    "las líneas 7 y 9 del ejemplo anterior. Construya un gráfico que muestre los coeficientes obtenidos\n",
    "como función del parámetro de regularización. Describa lo que observa. ¿Es más efectivo Lasso para\n",
    "seleccionar atributos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "alphas_ = np.logspace(0,-3,base=10)\n",
    "model = Lasso(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Escogiendo uno de los dos métodos regularizadores anteriores, especificando el porqué, construya un\n",
    "gráfico que muestre el error de entrenamiento y el error de pruebas como función del parámetro de\n",
    "regularización. Discuta lo que observa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X2[np.logical_not(istrain)]\n",
    "ytest = y[np.logical_not(istrain)]\n",
    "alphas_ = #choose it\n",
    "coefs = []\n",
    "model = #choose it\n",
    "mse_test = []\n",
    "mse_train = []\n",
    "for a in alphas_:\n",
    "model.set_params(alpha=a)\n",
    "model.fit(Xtrain, ytrain)\n",
    "yhat_train = model.predict(Xtrain)\n",
    "yhat_test = model.predict(Xtest)\n",
    "mse_train.append(np.mean(np.power(yhat_train - ytrain, 2)))\n",
    "mse_test.append(np.mean(np.power(yhat_test - ytest, 2)))\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas_,mse_train,label='train error ridge')\n",
    "ax.plot(alphas_,mse_test,label='test error ridge')\n",
    "plt.legend(loc=1)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Estime el valor del parámetro de regularización en **alguno** de los modelos anteriores haciendo uso de\n",
    "la técnica validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y,yhat): return np.mean(np.power(y-yhat,2))\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "best_cv_mse = float(\"inf\")\n",
    "model = #choose it\n",
    "alphas_ = #alphas to evaluate\n",
    "\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    mse_list_k10 = [MSE(model.fit(Xm[train], ym[train]).predict(Xm[val]), ym[val]) for train, val in kf.split(Xm)]\n",
    "    if np.mean(mse_list_k10) < best_cv_mse:\n",
    "        best_cv_mse = np.mean(mse_list_k10)\n",
    "        best_alpha = a\n",
    "        print \"BEST PARAMETER=%f, MSE(CV)=%f\"%(best_alpha,best_cv_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.- Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se presentarán dos muestras del dataframe utilizado en la actividades anteriores, donde cada\n",
    "una de estas tiene una propiedad distinta ya que son muestreadas en función del valor a predecir (logaritmo\n",
    "del precio de la casa). Por una parte se tiene una pequeña muestra A, la cual es extraída directamente de\n",
    "los datos con los que se trabaja (manteniendo la distribución de esta) y la muestra B, es generada con el\n",
    "propósito de que en cada intervalo del rango de valores haya la misma cantidad de datos aproximadamente\n",
    "(simulando una distribución uniforme). El objetivo es familiarizarse con el concepto de Transfer Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente código se generan las dos muestras con las que se trabajará."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"kc_house_data.csv\")\n",
    "df.drop(['id','date','zipcode',],axis=1,inplace=True)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_scaled['price'] = np.log(df['price'])\n",
    "\n",
    "df_A = df_scaled.sample(1000,random_state=11)\n",
    "frames = []\n",
    "valor = df_scaled.price\n",
    "length = 0.3\n",
    "for z in np.arange(int(np.min(valor)),int(np.max(valor))+1,length):\n",
    "    #un maximo de 100 datos por intervalo\n",
    "    aux = df_scaled[(df_scaled.price >= z) & (df_scaled.price < z+length)].head(100)\n",
    "    frames.append(aux)\n",
    "df_B = pd.concat(frames).sample(1000,random_state=11) #crea el dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Cree el conjunto de entrenamiento y otro de validación para trabajar cada muestra mediante la técnica\n",
    "de hold out validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_A = df_A.iloc[:,1:].values\n",
    "y_A = df_A.price\n",
    "X_B = df_B.iloc[:,1:].values\n",
    "y_B = df_B.price\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain_A,Xval_A,ytrain_A,yval_A = train_test_split(X_A, y_A, test_size=0.3, random_state=42)\n",
    "Xtrain_B,Xval_B,ytrain_B,yval_B = train_test_split(X_B, y_B, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Evalúe los dos modelo de regresión lineal que se generan al entrenar con cada muestra. Mida el error\n",
    "de cada modelo sobre ambos conjuntos de validación (A y B). Explique lo que observa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_A = linear_model.LinearRegression(fit_intercept=False)\n",
    "model_A = lm_A.fit(Xtrain_A, ytrain_A)\n",
    "predictions_A = model_A.predict(Xval_A)\n",
    "\n",
    "lm_B = linear_model.LinearRegression(fit_intercept=False)\n",
    "model_B = lm_B.fit(Xtrain_B, ytrain_B)\n",
    "predictions_B = model_B.predict(Xval_B)\n",
    "\n",
    "# print(predictions_A, predictions_B)\n",
    "\n",
    "print(\"Score_A_A:\", model_A.score(Xval_A, yval_A))\n",
    "print(\"Score_A_B:\", model_A.score(Xval_B, yval_B))\n",
    "print(\"Score_B_B:\", model_B.score(Xval_B, yval_B))\n",
    "print(\"Score_B_A:\", model_A.score(Xval_A, yval_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar por simple inspección que el score de ambos modelos para el conjunto A es mayor que para el conjunto B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Si tuviera que elegir uno de los dos modelos anteriores para trabajar con data futura, ¿Cuál eligiría y\n",
    "por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basado netamente en los scores obtenidos, el modelo B tendría mejores resultados, tanto para el conjunto A como el conjunto B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.- Detectar enfermedades cardiacas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el área de la salud, diagnosticar a una persona de una enfermedad de forma rápida y correcta puede llegar a salvarle la vida. Los encargados de realizar estos diagnósticos, son médicos que, observando exámenes y ciertos indicadores, pueden concluir qué enfermedad presenta el paciente. Si el medico se llegase a equivocar, aparte de que el paciente pueda perder la vida, el medico podría ser demandado por negligencia arriesgando años de cárcel o pagar sumas de dinero considerable, es por estas razones que es importante no cometer\n",
    "errores.\n",
    "Pongámonos en el contexto de que usted es contratado para generar un modelo que prediga si es que un paciente presenta una enfermedad cardiaca a partir de ciertos indicadores, tales como la edad, sexo, presión sanguínea, nivel de glicemia, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ayuda se le indica que la variable de máximo ritmo cardíaco alcanzado (maximum heart rate achieved) es un buen indicador de detección de enfermedades cardíacas. Por lo que el objetivo es predecir el comportamiento de esta variable en función de las otras, y con esto detectar qué tan distante es el valor real al valor predecido para así luego detectar los posibles outliers (enfermos), que en sí corresponden a pacientes que tienen un comportamiento anormal al resto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Lea el archivo de datos, cárguelos en un dataframe o matriz, luego divida el dataframe en dos, un\n",
    "dataframe de entrenamiento (70% Datos) y un dataframe de prueba (30% Datos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "headers = ['age','sex','chest_pain','blood_p','serum','blood_s','electro','max_heart','angina','oldpeak','slope','vessel','thal','normal']\n",
    "df = pd.read_csv('heart.csv', header=None, names=headers, sep=',')\n",
    "\n",
    "y = df['max_heart']\n",
    "# train_n = int(len(df)*0.7)\n",
    "# X_train, X_test = df[-train_n:], df[:-train_n] \n",
    "# y_train, y_test = y[-train_n:], y[:-train_n] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[headers], y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_test_normal = X_test['normal']\n",
    "X_test_heart = X_test['max_heart']\n",
    "X_train.drop(['max_heart','normal'],axis=1,inplace=True)\n",
    "X_test.drop(['max_heart','normal'],axis=1,inplace=True)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Realice una regresión lineal y defina usted una frontera de decisión (umbral) para poder determinar si\n",
    "es que estamos en presencia o no de una enfermedad cardíaca. Mida su desempeño con ambos conjuntos\n",
    "de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression(fit_intercept=False)\n",
    "model = lm.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "y_mean = y_train.mean()\n",
    "\n",
    "lm2 = linear_model.LinearRegression(fit_intercept=False)\n",
    "model2 = lm2.fit(X_test_heart.values.reshape(-1, 1), X_test_normal)\n",
    "\n",
    "compare = pd.DataFrame({'Y': y_test,'y_': predictions})\n",
    "compare['y_'] = compare['y_'].round(0)\n",
    "compare['R'] = compare.apply(lambda x: (x.Y-x.y_)**2, axis=1)\n",
    "compare['R_2'] = compare.apply(lambda x: (x.Y**2 + y_mean**2)**(1/2), axis=1)\n",
    "compare['n_1'] = compare.apply(lambda x: (1 if x.R >= x.R_2 else 2), axis=1)\n",
    "compare['n_2'] = model2.predict(compare['y_'].values.reshape(-1, 1)).round(0)\n",
    "compare['n_3'] = compare.apply(lambda x: (1 if x.n_1+x.n_2 <= 2 else 2), axis=1)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Score n_1:  %f\"%(accuracy_score(X_test_normal,compare['n_1'])))\n",
    "print(\"Score n_2:  %f\"%(accuracy_score(X_test_normal,compare['n_2'])))\n",
    "print(\"Score n_3:  %f\"%(accuracy_score(X_test_normal,compare['n_3'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
