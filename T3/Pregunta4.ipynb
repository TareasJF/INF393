{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Construya una funci´on que cargue todos los datos de entrenamiento y pruebas del problema generando\n",
    "como salida: (i) dos matrices Xtr, Ytr, correspondientes a las im´agenes y etiquetas de entrenamiento,\n",
    "(ii) dos matrices Xt, Yt, correspondientes a las im´agenes y etiquetas de pruebas, y finalmente (iii) dos\n",
    "matrices Xv, Yv, correspondientes a im´agenes y etiquetas que se usar´an como conjunto de validaci´on, es\n",
    "decir para tomar decisiones de dise˜no acerca del modelo. Este ´ultimo conjunto debe ser extra´ıdo desde\n",
    "el conjunto de entrenamiento original y no debe superar las 7000 im´agenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "def load_data():\n",
    "    train = pd.read_csv('data/sign_mnist_train.csv')\n",
    "    test = pd.read_csv('data/sign_mnist_test.csv')\n",
    "    (train_set, validation_set) = train_test_split(train, test_size=7000, random_state=8500)\n",
    "    \n",
    "    y_tr = train_set['label']\n",
    "    x_tr = train_set.iloc[:, 1:]\n",
    "    \n",
    "    y_t = test['label']\n",
    "    x_t = test.iloc[:, 1:]\n",
    "    \n",
    "    y_v = validation_set['label']\n",
    "    x_v = validation_set.iloc[:, 1:]\n",
    "\n",
    "    return(x_tr,x_v,x_t,y_tr,y_v,y_t)\n",
    "x_tr, x_v, x_t, y_tr, y_v , y_t = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Construya una funci´on que escale apropiadamente las im´agenes antes de trabajar. Experimente s´olo\n",
    "escalando los datos de acuerdo a la intensidad m´axima de pixel (i.e., dividiendo por 255) y luego\n",
    "centrando y escal´andolos como en actividades anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_by_max_pixel(x_set):\n",
    "    return x_set/255\n",
    "\n",
    "\n",
    "# Finish this one!\n",
    "def center_and_scale(x_set):\n",
    "    return x_set\n",
    "x_tr = scale_by_max_pixel(x_tr)\n",
    "x_t = scale_by_max_pixel(x_t)\n",
    "x_v = scale_by_max_pixel(x_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Dise˜ne, entrene y eval´ue una red neuronal para el problema partir de la representaci´on original de las\n",
    "im´agenes. Experimente con distintas arquitecturas, pre-procesamientos y m´etodos de entrenamiento, midiendo el error de clasificaci´on sobre el conjunto de validaci´on. En base a esta ´ultima medida de\n",
    "desempe˜no, decida qu´e modelo, de entre todos los evaluados, medir´a finalmente en el conjunto de test.\n",
    "Reporte y discuta los resultados obtenidos. Se espera que logre obtener un error de pruebas menor o\n",
    "igual a 0.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=784, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20455 samples, validate on 7000 samples\n",
      "Epoch 1/100\n",
      "20455/20455 [==============================] - 1s 53us/step - loss: 3.0655 - acc: 0.0857 - val_loss: 2.8185 - val_acc: 0.1417\n",
      "Epoch 2/100\n",
      "20455/20455 [==============================] - 1s 41us/step - loss: 2.6613 - acc: 0.1768 - val_loss: 2.5034 - val_acc: 0.2154\n",
      "Epoch 3/100\n",
      "20455/20455 [==============================] - 1s 42us/step - loss: 2.4059 - acc: 0.2275 - val_loss: 2.3405 - val_acc: 0.2299\n",
      "Epoch 4/100\n",
      "20455/20455 [==============================] - 1s 42us/step - loss: 2.2743 - acc: 0.2417 - val_loss: 2.3140 - val_acc: 0.2296\n",
      "Epoch 5/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 2.2025 - acc: 0.2582 - val_loss: 2.1759 - val_acc: 0.2569\n",
      "Epoch 6/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 2.1331 - acc: 0.2781 - val_loss: 2.1243 - val_acc: 0.2780\n",
      "Epoch 7/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 2.0518 - acc: 0.3083 - val_loss: 2.0101 - val_acc: 0.3144\n",
      "Epoch 8/100\n",
      "20455/20455 [==============================] - 1s 42us/step - loss: 1.9598 - acc: 0.3404 - val_loss: 1.9041 - val_acc: 0.3634\n",
      "Epoch 9/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 1.8581 - acc: 0.3797 - val_loss: 1.8655 - val_acc: 0.3847\n",
      "Epoch 10/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 1.7728 - acc: 0.4091 - val_loss: 1.7315 - val_acc: 0.4350\n",
      "Epoch 11/100\n",
      "20455/20455 [==============================] - 1s 36us/step - loss: 1.7015 - acc: 0.4304 - val_loss: 1.6441 - val_acc: 0.4647\n",
      "Epoch 12/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 1.6436 - acc: 0.4483 - val_loss: 1.6253 - val_acc: 0.4580\n",
      "Epoch 13/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 1.5880 - acc: 0.4658 - val_loss: 1.7249 - val_acc: 0.4149\n",
      "Epoch 14/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 1.5483 - acc: 0.4810 - val_loss: 1.5253 - val_acc: 0.4964\n",
      "Epoch 15/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 1.5036 - acc: 0.4975 - val_loss: 1.5715 - val_acc: 0.4609\n",
      "Epoch 16/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 1.4706 - acc: 0.5055 - val_loss: 1.5026 - val_acc: 0.4963\n",
      "Epoch 17/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 1.4301 - acc: 0.5198 - val_loss: 1.5824 - val_acc: 0.4569\n",
      "Epoch 18/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 1.3992 - acc: 0.5274 - val_loss: 1.3765 - val_acc: 0.5361\n",
      "Epoch 19/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 1.3572 - acc: 0.5414 - val_loss: 1.3530 - val_acc: 0.5510\n",
      "Epoch 20/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 1.3278 - acc: 0.5497 - val_loss: 1.4835 - val_acc: 0.5003\n",
      "Epoch 21/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 1.2986 - acc: 0.5598 - val_loss: 1.2620 - val_acc: 0.5746\n",
      "Epoch 22/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 1.2635 - acc: 0.5695 - val_loss: 1.3508 - val_acc: 0.5494\n",
      "Epoch 23/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 1.2348 - acc: 0.5752 - val_loss: 1.2311 - val_acc: 0.5744\n",
      "Epoch 24/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 1.2032 - acc: 0.5857 - val_loss: 1.2011 - val_acc: 0.5936\n",
      "Epoch 25/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 1.1772 - acc: 0.5952 - val_loss: 1.2679 - val_acc: 0.5756\n",
      "Epoch 26/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 1.1425 - acc: 0.6055 - val_loss: 1.0959 - val_acc: 0.6294\n",
      "Epoch 27/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 1.1108 - acc: 0.6167 - val_loss: 1.1276 - val_acc: 0.6253\n",
      "Epoch 28/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 1.0820 - acc: 0.6265 - val_loss: 1.1094 - val_acc: 0.6184\n",
      "Epoch 29/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 1.0461 - acc: 0.6388 - val_loss: 1.0463 - val_acc: 0.6429\n",
      "Epoch 30/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 1.0204 - acc: 0.6444 - val_loss: 1.0342 - val_acc: 0.6453\n",
      "Epoch 31/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.9878 - acc: 0.6593 - val_loss: 0.9959 - val_acc: 0.6496\n",
      "Epoch 32/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 0.9549 - acc: 0.6698 - val_loss: 0.9389 - val_acc: 0.6849\n",
      "Epoch 33/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.9270 - acc: 0.6795 - val_loss: 0.9902 - val_acc: 0.6609\n",
      "Epoch 34/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.9004 - acc: 0.6883 - val_loss: 0.8509 - val_acc: 0.7091\n",
      "Epoch 35/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.8734 - acc: 0.6958 - val_loss: 0.9674 - val_acc: 0.6586\n",
      "Epoch 36/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.8504 - acc: 0.7037 - val_loss: 0.8797 - val_acc: 0.7050\n",
      "Epoch 37/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.8220 - acc: 0.7123 - val_loss: 0.9697 - val_acc: 0.6500\n",
      "Epoch 38/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.8036 - acc: 0.7240 - val_loss: 0.8362 - val_acc: 0.7053\n",
      "Epoch 39/100\n",
      "20455/20455 [==============================] - 1s 34us/step - loss: 0.7776 - acc: 0.7269 - val_loss: 0.7458 - val_acc: 0.7539\n",
      "Epoch 40/100\n",
      "20455/20455 [==============================] - 1s 34us/step - loss: 0.7582 - acc: 0.7381 - val_loss: 0.7578 - val_acc: 0.7417\n",
      "Epoch 41/100\n",
      "20455/20455 [==============================] - 1s 34us/step - loss: 0.7433 - acc: 0.7421 - val_loss: 0.6988 - val_acc: 0.7573\n",
      "Epoch 42/100\n",
      "20455/20455 [==============================] - 1s 34us/step - loss: 0.7140 - acc: 0.7488 - val_loss: 0.9897 - val_acc: 0.6577\n",
      "Epoch 43/100\n",
      "20455/20455 [==============================] - 1s 34us/step - loss: 0.7020 - acc: 0.7571 - val_loss: 0.6890 - val_acc: 0.7560\n",
      "Epoch 44/100\n",
      "20455/20455 [==============================] - 1s 34us/step - loss: 0.6786 - acc: 0.7633 - val_loss: 0.7947 - val_acc: 0.7204\n",
      "Epoch 45/100\n",
      "20455/20455 [==============================] - 1s 34us/step - loss: 0.6682 - acc: 0.7660 - val_loss: 0.7910 - val_acc: 0.7177\n",
      "Epoch 46/100\n",
      "20455/20455 [==============================] - 1s 34us/step - loss: 0.6390 - acc: 0.7752 - val_loss: 0.6907 - val_acc: 0.7597\n",
      "Epoch 47/100\n",
      "20455/20455 [==============================] - 1s 34us/step - loss: 0.6190 - acc: 0.7828 - val_loss: 0.6516 - val_acc: 0.7711\n",
      "Epoch 48/100\n",
      "20455/20455 [==============================] - 1s 34us/step - loss: 0.6053 - acc: 0.7875 - val_loss: 0.6397 - val_acc: 0.7846\n",
      "Epoch 49/100\n",
      "20455/20455 [==============================] - 1s 34us/step - loss: 0.5878 - acc: 0.7947 - val_loss: 0.5684 - val_acc: 0.8071\n",
      "Epoch 50/100\n",
      "20455/20455 [==============================] - 1s 34us/step - loss: 0.5712 - acc: 0.8004 - val_loss: 0.5507 - val_acc: 0.8054\n",
      "Epoch 51/100\n",
      "20455/20455 [==============================] - 1s 34us/step - loss: 0.5576 - acc: 0.8087 - val_loss: 0.5315 - val_acc: 0.8201\n",
      "Epoch 52/100\n",
      "20455/20455 [==============================] - 1s 34us/step - loss: 0.5348 - acc: 0.8132 - val_loss: 0.4747 - val_acc: 0.8389\n",
      "Epoch 53/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.5234 - acc: 0.8172 - val_loss: 0.5303 - val_acc: 0.8141\n",
      "Epoch 54/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.5058 - acc: 0.8258 - val_loss: 0.5428 - val_acc: 0.8086\n",
      "Epoch 55/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.4945 - acc: 0.8302 - val_loss: 0.4471 - val_acc: 0.8474\n",
      "Epoch 56/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.4771 - acc: 0.8330 - val_loss: 0.4109 - val_acc: 0.8671\n",
      "Epoch 57/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.4652 - acc: 0.8365 - val_loss: 0.4500 - val_acc: 0.8439\n",
      "Epoch 58/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.4479 - acc: 0.8476 - val_loss: 0.4871 - val_acc: 0.8301\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20455/20455 [==============================] - 1s 42us/step - loss: 0.4369 - acc: 0.8538 - val_loss: 0.4439 - val_acc: 0.8351\n",
      "Epoch 60/100\n",
      "20455/20455 [==============================] - 1s 36us/step - loss: 0.4265 - acc: 0.8520 - val_loss: 0.3531 - val_acc: 0.8853\n",
      "Epoch 61/100\n",
      "20455/20455 [==============================] - 1s 37us/step - loss: 0.4076 - acc: 0.8604 - val_loss: 0.4604 - val_acc: 0.8387\n",
      "Epoch 62/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 0.4040 - acc: 0.8628 - val_loss: 0.4857 - val_acc: 0.8214\n",
      "Epoch 63/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.3809 - acc: 0.8698 - val_loss: 0.3882 - val_acc: 0.8650\n",
      "Epoch 64/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 0.3716 - acc: 0.8757 - val_loss: 0.5971 - val_acc: 0.7847\n",
      "Epoch 65/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 0.3667 - acc: 0.8710 - val_loss: 0.3636 - val_acc: 0.8631\n",
      "Epoch 66/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 0.3516 - acc: 0.8792 - val_loss: 0.4464 - val_acc: 0.8473\n",
      "Epoch 67/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 0.3430 - acc: 0.8829 - val_loss: 0.2947 - val_acc: 0.8960\n",
      "Epoch 68/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.3248 - acc: 0.8870 - val_loss: 0.4148 - val_acc: 0.8451\n",
      "Epoch 69/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.3189 - acc: 0.8938 - val_loss: 0.2977 - val_acc: 0.9009\n",
      "Epoch 70/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.3104 - acc: 0.8956 - val_loss: 0.2507 - val_acc: 0.9194\n",
      "Epoch 71/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.2955 - acc: 0.9020 - val_loss: 0.2628 - val_acc: 0.9073\n",
      "Epoch 72/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.2959 - acc: 0.9015 - val_loss: 0.2098 - val_acc: 0.9347\n",
      "Epoch 73/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.2828 - acc: 0.9074 - val_loss: 0.4496 - val_acc: 0.8509\n",
      "Epoch 74/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.2685 - acc: 0.9121 - val_loss: 0.4013 - val_acc: 0.8556\n",
      "Epoch 75/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.2557 - acc: 0.9140 - val_loss: 0.6245 - val_acc: 0.7810\n",
      "Epoch 76/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.2530 - acc: 0.9188 - val_loss: 0.3622 - val_acc: 0.8630\n",
      "Epoch 77/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.2376 - acc: 0.9202 - val_loss: 0.2863 - val_acc: 0.8950\n",
      "Epoch 78/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.2359 - acc: 0.9227 - val_loss: 0.4208 - val_acc: 0.8424\n",
      "Epoch 79/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.2342 - acc: 0.9255 - val_loss: 0.1573 - val_acc: 0.9549\n",
      "Epoch 80/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 0.2192 - acc: 0.9294 - val_loss: 0.1944 - val_acc: 0.9414\n",
      "Epoch 81/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.2138 - acc: 0.9312 - val_loss: 0.1365 - val_acc: 0.9647\n",
      "Epoch 82/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.2046 - acc: 0.9338 - val_loss: 0.1981 - val_acc: 0.9326\n",
      "Epoch 83/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.2018 - acc: 0.9366 - val_loss: 0.1211 - val_acc: 0.9694\n",
      "Epoch 84/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.1911 - acc: 0.9376 - val_loss: 0.1364 - val_acc: 0.9593\n",
      "Epoch 85/100\n",
      "20455/20455 [==============================] - 1s 40us/step - loss: 0.1832 - acc: 0.9449 - val_loss: 0.4587 - val_acc: 0.8439\n",
      "Epoch 86/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.1773 - acc: 0.9442 - val_loss: 0.1767 - val_acc: 0.9466\n",
      "Epoch 87/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.1737 - acc: 0.9487 - val_loss: 0.2745 - val_acc: 0.8974\n",
      "Epoch 88/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.1715 - acc: 0.9477 - val_loss: 0.1142 - val_acc: 0.9694\n",
      "Epoch 89/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.1647 - acc: 0.9496 - val_loss: 0.1163 - val_acc: 0.9686\n",
      "Epoch 90/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.1523 - acc: 0.9559 - val_loss: 0.1824 - val_acc: 0.9320\n",
      "Epoch 91/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.1624 - acc: 0.9521 - val_loss: 0.1042 - val_acc: 0.9736\n",
      "Epoch 92/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.1468 - acc: 0.9584 - val_loss: 0.0823 - val_acc: 0.9834\n",
      "Epoch 93/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.1566 - acc: 0.9557 - val_loss: 0.0899 - val_acc: 0.9766\n",
      "Epoch 94/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.1306 - acc: 0.9621 - val_loss: 0.1981 - val_acc: 0.9219\n",
      "Epoch 95/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.1342 - acc: 0.9598 - val_loss: 0.3084 - val_acc: 0.8889\n",
      "Epoch 96/100\n",
      "20455/20455 [==============================] - 1s 39us/step - loss: 0.1373 - acc: 0.9599 - val_loss: 0.4721 - val_acc: 0.8437\n",
      "Epoch 97/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.1316 - acc: 0.9625 - val_loss: 0.1373 - val_acc: 0.9499\n",
      "Epoch 98/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.1280 - acc: 0.9633 - val_loss: 0.0582 - val_acc: 0.9889\n",
      "Epoch 99/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.1195 - acc: 0.9674 - val_loss: 0.1850 - val_acc: 0.9273\n",
      "Epoch 100/100\n",
      "20455/20455 [==============================] - 1s 38us/step - loss: 0.1262 - acc: 0.9670 - val_loss: 0.0470 - val_acc: 0.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x121673cf8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Creación de red secuencial\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=x_tr.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dense(30, init='uniform', activation='relu'))\n",
    "model.add(Dense(25, init='uniform', activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_tr.values, to_categorical(y_tr), nb_epoch=100, batch_size=128, verbose=1,\n",
    "validation_data=(x_v.values,to_categorical(y_v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error de clasificación: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Para la mejor red entrenada anteriormente construya la matriz de confusi´on de las distintas clases, para\n",
    "asi visualizar cu´ales son las clases m´as dif´ıciles de clasificar y con cu´ales se confunden. Comente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAywAAANHCAYAAADUvdkEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121b039b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_t_predict = model.predict_classes(x_t.values)\n",
    "cm = confusion_matrix(y_t, y_t_predict)\n",
    "    \n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Entrene una SVM no lineal sobre los pixeles con y sin pre-procesamiento. Puede utilizar el conjunto de\n",
    "validaci´on para seleccionar hiper-par´ametros, como el nivel de regularizaci´on aplicado y/o la funci´on\n",
    "de kernel a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f)** Entrene una ´arbol de clasificaci´on sobre los pixeles con y sin pre-procesamiento. Puede utilizar el\n",
    "conjunto de validaci´on para seleccionar hiper-par´ametros, como la profundidad m´axima del ´arbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
